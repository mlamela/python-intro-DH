{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5884a7f-3a86-48f1-b4ed-ef3571dd46b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction to Cultural Analytics (ht-2023)\n",
    "\n",
    "Matti La Mela, matti.lamela@abm.uu.se\n",
    "\n",
    "### Lab material 1b: reading and writing files\n",
    "\n",
    "This Notebook introduces us to how to open and write txt files. We are able to take external text data for our python data processing. Later we will open csv-files with pandas.\n",
    "\n",
    "The reference readings for this learning material is\n",
    "\n",
    "o Chapter 9 in Allen B. Downey Think Python: How to Think Like a Computer Scientist, 2nd ed., Needham 2015, https://greenteapress.com/wp/think-python-2e/\n",
    "\n",
    "o \"Files and character encoding\" in Walsh, M. (2021). Introduction to Cultural Analytics and Python. https://melaniewalsh.github.io/Intro-Cultural-Analytics/welcome.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79ce28-cab9-4ff9-b42d-5345ca2caaf4",
   "metadata": {},
   "source": [
    "## 1. Reading a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a2058-96d3-41b3-be30-e2588aa169fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will read the text file into a string variable that we label \"book\". This includes all the characters the text file might\n",
    "# contain including extra spaces, OCR-dirt, line breaks. These we might have to clean later.\n",
    "\n",
    "# We use the open() function to open our file. We give as arguments the path, mode, and file encoding.\n",
    "# We use mode = \"r\", while we are reading the file. We will use later \"w\" (writes over the old file) or \"a\" (append, adds to the existing file).\n",
    "\n",
    "# The with statement here ensures simply that we do not leave the file open. We should close it with close(). Python is good in handling files that never\n",
    "# get closed, but for example when writing we need to close the file to have it actually written.\n",
    "\n",
    "# Note the indentation again: everything that is in the indented code block is done while the file is open!\n",
    "\n",
    "with open(\"./texts_week1/Alice_in_wonderland.txt\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    book = file.read()\n",
    "    \n",
    "print(len(book))\n",
    "print(book[0:500])\n",
    "\n",
    "# We print the length of the book, and use the index to print the five hundred first characters of \n",
    "# the Alice's adventures in Wonderland by Lewis Carroll (https://www.gutenberg.org/ebooks/11)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42292ff2-411b-4cd2-bf5a-7b901c638de2",
   "metadata": {},
   "source": [
    "## 2. Some data processing with the text data we have read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a95e65-adce-45ec-ba95-58aa0abbe933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want remove the information about the ebook and start from chapter 1. We know that the opening sentence is \"Alice was beginning to get very\" etc.\n",
    "\n",
    "# .index() string method gives us the index number where a sub-string is found.\n",
    "\n",
    "start = book.index(\"Alice was beginning\")\n",
    "\n",
    "print (book[start:start+100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf73c29-121f-40ba-84ee-fca4e376a7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We then replace our \"book\" string with the slice of the \"book\" that starts from the index \"start\" and runs until the end of the string\n",
    "\n",
    "book_ch1 = book[start:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160b9f5-1e3b-466c-914a-fd967916e535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We continue with processing our text data. For the method that we plan to use, we want the text in lower case.\n",
    "\n",
    "book_ch1 = book_ch1.lower()\n",
    "\n",
    "print(book_ch1[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca30ac-a345-438e-b02f-d30b4c511ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Also, we want to assign the text paragraphs into a list. With split() method, we can split the parts between two endlines \\n\\n, which mark the\n",
    "# paragraph here\n",
    "\n",
    "book_paragraphs = book_ch1.split(\"\\n\\n\")\n",
    "\n",
    "print(book_paragraphs[0:3])\n",
    "\n",
    "# we should see now first three paragraphs of the novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc6b65-4b7d-4e80-aa89-ce513842e689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We see that the paragraphs contain endlines, \\n. Our hypothetical method processes only words, so we could replace the endlines with space.\n",
    "\n",
    "# We use for loop to iterate through our list of paragraphs. We can use range, but another way is to create a variable that follows \n",
    "# the index number of the list.\n",
    "\n",
    "for i in range(len(book_paragraphs)):\n",
    "    book_paragraphs[i] = book_paragraphs[i].replace(\"\\n\", \" \")\n",
    "\n",
    "print(book_paragraphs[0:5])\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae8d52-3223-40ff-b25f-de702d644350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Depending on our needs, e.g., in what format should we have the text ready for our analysis, we could continue the processing even further.\n",
    "\n",
    "# We want to write the text to a file, which we do in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6270a24e-49bd-49f5-b93b-ca6ffa707c85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ps. One useful string method for cleaning strings is .strip(\"CHAR\")\n",
    "\n",
    "# This removes the CHAR from the beginning and end of a string. If no CHAR is given strip removes whitespaces.\n",
    "\n",
    "# In this example string there are extra whitespaces at the beginning and at the end\n",
    "\n",
    "example = \"     this is our data   \"\n",
    "\n",
    "cleaned = example.strip()\n",
    "\n",
    "print(cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c358a-98c5-4930-8a5f-2199ee2ef7e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Writing to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cc32c-697c-470f-bec1-109fdae897f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Writing to text file is done in a similar way like when reading a file, but we use the mode \"w\".\n",
    "\n",
    "# Note what mode \"w\" overwrites any existing file. If we want to append, thus to add new content to the file, we can use mode \"a\" when writing.\n",
    "# We use utf-8 encoding for our files.\n",
    "#\n",
    "# There are several ways to write our list to the file.\n",
    "\n",
    "# We can use a for loop for this. Note again the indentation, what are the blocks that are executed when the file is open (with),\n",
    "# and what is done in the for loop.\n",
    "#\n",
    "# In the for loop, we iterate through the cleaned_paragraphs list: each value (thus paragraph in our list) is assigned to \"text\". We write the\n",
    "# content of the text variable to the file \"output_paragraphs.txt\". We add also a breakline \\n.\n",
    "\n",
    "with open(\"./texts_week1/output_paragraphs.txt\", mode=\"w\", encoding=\"utf-8\") as file:\n",
    "    for paragraph in book_paragraphs:\n",
    "        file.write(paragraph)\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "# we should now have a file \"output_paragraphs\" in our texts_week1 folder. You can obviously use some other path also for this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c138feb-1e8e-4ea3-9a67-e368f23fde39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It is very easy to unite a list of strings together with the .join method. The string given to join is what is put\n",
    "# between the list entries.\n",
    "\n",
    "# Example with our book titles:\n",
    "\n",
    "book_titles = [\"Introduction to Cultural Analytics & Python\", \"Distant Horizons\", \"Data Feminism\"]\n",
    "\n",
    "print(book_titles)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# We join the list into a string variable. We give space, \" \", as the connecting string. This could any string that we might want as a connector.\n",
    "\n",
    "titles_string = \" \".join(book_titles)\n",
    "\n",
    "print(titles_string)\n",
    "\n",
    "# The first line of output is a list of strings, the lower one is a string where we have concatenated the list entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c379e40-c9bc-4695-ba4a-3c09a4420fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's use join() method to unite our paragraphs into a string, and then write the string to a file. We use linebreak \"\\n\" as the connector:\n",
    "\n",
    "text = \"\\n\".join(book_paragraphs)\n",
    "\n",
    "# we overwrite the file \"output_paragraphs.txt\".\n",
    "\n",
    "with open(\"./texts_week1/output_paragraphs.txt\", mode=\"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614d24c-bbfd-4910-878f-70dc9b13b837",
   "metadata": {},
   "source": [
    "### Well done. You can try opening the text file (output_paragraphs.txt) in a text processing program, e.g. notepad++ or word.\n",
    "\n",
    "We see that there are still empty paragraphs written to our file. You can reflect on about what in our cleaning process left these empty spaces. Perhaps our process could be simplified?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afffdb57-4f3f-452c-8a3e-36db18f12d2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Reading multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c7e87-ee6f-4acc-83d2-4d5dd139e729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We often want to open several files instead of just one. This enables us to scale our research.\n",
    "\n",
    "# We import the module glob that allows us to search for filenames in a path. We can use the result for reading the files name by name.\n",
    "\n",
    "import glob\n",
    "\n",
    "# Let us see what text files we have in our texts_week1 path. If we use the wild card *.txt, we get all the files that are of txt file\n",
    "# extension. We have other txt-files in the directory, so we use the more specific expression dhq*.txt: all .txt files that start with dhq.\n",
    "\n",
    "# Glob creates a list of the file names:\n",
    "\n",
    "list_files = glob.glob(\"./texts_week1/dhq*.txt\")\n",
    "\n",
    "# Let's print the first five filenames:\n",
    "\n",
    "for filename in list_files[0:10]:\n",
    "    print(filename)\n",
    "\n",
    "#print(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be2129-a549-449a-b6da-4b80b0059b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We open every file in our list_files in a for loop. This could be  and do other relevant operations with them (e.g. data cleaning could be done here).\n",
    "\n",
    "# In this example we save our files as strings to a list (\"texts\"), where we could then continue working with them.\n",
    "\n",
    "text_content = []\n",
    "text_filename = []\n",
    "\n",
    "\n",
    "for filename in list_files:\n",
    "    with open(filename, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        article = file.read()\n",
    "        text_content.append(article)\n",
    "        text_filename.append(filename[14:])  # we save the filenames to a list text_filename. We know that \"dhq\" is always at index 14 in the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829981b0-cc3e-4a87-9402-9774b2f5bc0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's print the filename of the first article and the 1000 characters of the first article.\n",
    "# Frst index is for the list element [0], and the second for the range in the string [0:1000]\n",
    "\n",
    "print(text_filename[0])\n",
    "print(text_content[0][0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84258e98-cdd4-40cd-a74e-0f1c65d8b3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We would next work with the articles, or process them into a some more suitable format.\n",
    "\n",
    "# If we want to write the processed content back to txt-files, we need to establish new filenames (if we don't want to overwrite the original files).\n",
    "# We can create another list (\"write_filename\") with the new filenames.\n",
    "\n",
    "write_filename = []\n",
    "\n",
    "for i in range(len(text_filename)):\n",
    "    filename = \"./texts_week1/processed-\" + text_filename[i]  # we add the write path and the text \"processed-\" before the actual file name\n",
    "    write_filename.append(filename)\n",
    "\n",
    "# And let's print the first filename in the list.\n",
    "\n",
    "print(write_filename[0])\n",
    "\n",
    "# Now we could iterate this list (write_filename), like we did when opened the files, but instead of parameter \"r\", we use \"w\" and write the processed data to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8301ea5a-e2f1-49f7-b4cc-979a14d04607",
   "metadata": {
    "tags": []
   },
   "source": [
    "## We are now done for the labs for week 1. It is good to revise the Python basics from the course textbook. You can now start doing the first lab assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ce0960-744c-4a5a-98e7-49a9df32fa18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e3b7ca-03d4-44b0-aca9-4ce6e8d7e817",
   "metadata": {},
   "source": [
    "Ps.\n",
    "\n",
    "Why do we use the encoding = utf-8 when opening files? This is to ensure that we open the file with the right encoding (in this case: utf-8). Otherwise open() uses the computer's default encoding, which might be something else, and might lead to an error.\n",
    "\n",
    "Utf-8 is the most common encoding today, https://en.wikipedia.org/wiki/Popularity_of_text_encodings, and it covers the whole very encompassing Unicode character set (Unicode 15.0.0 has 149,185 characters, https://www.unicode.org/versions/Unicode15.0.0/). For example, some historical character sets like ASCII had just 95 printable characters. It is thus good to save your text data into utf-8 to ensure compatibility, and if the file is in some different format, it can be converted for example with Notepad++ to utf-8. You can read more about character encodings at https://dsc.gmu.edu/tutorials-data/tutorial-character-encoding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b41903-6388-42a5-ba6e-f276e9761922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you want to see what kind of unicode characters there are, you can print the first 10000 chars with this for loop:\n",
    "\n",
    "i = 0\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    print(chr(i))\n",
    "    \n",
    "# There are even emojis included..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ede4a2-3886-4863-8753-4e8303eda277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
